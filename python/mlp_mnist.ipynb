{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mnist as mnist\n",
    "from hgen import write_model\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "seed(1)\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image data so each image is represented by one long array \n",
    "def prepare_input(arr):\n",
    "    arr = arr.reshape(arr.shape[0], arr.shape[1] * arr.shape[2])\n",
    "    \n",
    "    # Convert to input float32\n",
    "    arr = arr.astype('float32')\n",
    "\n",
    "    # Normalise input in the range [-1, 1] \n",
    "    arr = (arr-127.5) / 127.5\n",
    "\n",
    "    return arr\n",
    "\n",
    "def mem_usage(numpy_arr):\n",
    "    print('Uses {0:.2f} MB of memory'.format(numpy_arr.nbytes / 1024 / 1024))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.train_images()\n",
    "y = mnist.train_labels()\n",
    "X_test = mnist.test_images()\n",
    "y_test = mnist.test_labels()\n",
    "\n",
    "# Reshape and normalise input\n",
    "X = prepare_input(X)\n",
    "X_test = prepare_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.unique(y).shape[0]\n",
    "input_size = X.shape[1]\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y = keras.utils.to_categorical(y, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name='model'):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(X, y,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test))\n",
    "    model.save_weights('models/{}.hdf5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def create_mlp_3_layers_32():\n",
    "    inputs = Input(shape=(input_size,))\n",
    "    x = Dense(32, name='hidden', activation='relu')(inputs)\n",
    "    predictions = Dense(10, name='output', activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    return { 'model': model, 'name': 'mpl_3_layers_32' }\n",
    "\n",
    "mpl_3_layers_32 = create_mlp_3_layers_32()\n",
    "mpl_3_layers_32_model = mpl_3_layers_32['model']\n",
    "mpl_3_layers_32_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 337.00 221.00\" width=\"337pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 333,-217 333,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140506336826648 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140506336826648</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 329,-212.5 329,-166.5 0,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80\" y=\"-185.8\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"160,-166.5 160,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"160,-189.5 228,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"228,-166.5 228,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-197.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"228,-189.5 329,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278.5\" y=\"-174.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 140506336826816 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140506336826816</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-83.5 20.5,-129.5 308.5,-129.5 308.5,-83.5 20.5,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80\" y=\"-102.8\">hidden: Dense</text>\n",
       "<polyline fill=\"none\" points=\"139.5,-83.5 139.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"139.5,-106.5 207.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"173.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-83.5 207.5,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-114.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"207.5,-106.5 308.5,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-91.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 140506336826648&#45;&gt;140506336826816 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140506336826648-&gt;140506336826816</title>\n",
       "<path d=\"M164.5,-166.3799C164.5,-158.1745 164.5,-148.7679 164.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.0001,-139.784 164.5,-129.784 161.0001,-139.784 168.0001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140506336826928 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140506336826928</title>\n",
       "<polygon fill=\"none\" points=\"26,-.5 26,-46.5 303,-46.5 303,-.5 26,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84.5\" y=\"-19.8\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"143,-.5 143,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"143,-23.5 211,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"211,-.5 211,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-31.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"211,-23.5 303,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140506336826816&#45;&gt;140506336826928 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140506336826816-&gt;140506336826928</title>\n",
       "<path d=\"M164.5,-83.3799C164.5,-75.1745 164.5,-65.7679 164.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"168.0001,-56.784 164.5,-46.784 161.0001,-56.784 168.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(mpl_3_layers_32_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4755 - acc: 0.8550 - val_loss: 0.2948 - val_acc: 0.9140\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2878 - acc: 0.9152 - val_loss: 0.2654 - val_acc: 0.9192\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.2449 - acc: 0.9292 - val_loss: 0.2232 - val_acc: 0.9339\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2193 - acc: 0.9354 - val_loss: 0.2123 - val_acc: 0.9384\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.2016 - acc: 0.9407 - val_loss: 0.2272 - val_acc: 0.9348\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1871 - acc: 0.9452 - val_loss: 0.1815 - val_acc: 0.9473\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1756 - acc: 0.9475 - val_loss: 0.1801 - val_acc: 0.9462\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1651 - acc: 0.9518 - val_loss: 0.1702 - val_acc: 0.9493\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1579 - acc: 0.9527 - val_loss: 0.1745 - val_acc: 0.9479\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1490 - acc: 0.9557 - val_loss: 0.1516 - val_acc: 0.9563\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1436 - acc: 0.9573 - val_loss: 0.1668 - val_acc: 0.9528\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1395 - acc: 0.9582 - val_loss: 0.1560 - val_acc: 0.9539\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1343 - acc: 0.9600 - val_loss: 0.1607 - val_acc: 0.9526\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1298 - acc: 0.9603 - val_loss: 0.1496 - val_acc: 0.9568\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1246 - acc: 0.9627 - val_loss: 0.1470 - val_acc: 0.9571\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1241 - acc: 0.9623 - val_loss: 0.1547 - val_acc: 0.9544\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.1207 - acc: 0.9633 - val_loss: 0.1471 - val_acc: 0.9552\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1157 - acc: 0.9652 - val_loss: 0.1581 - val_acc: 0.9539\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.1147 - acc: 0.9658 - val_loss: 0.1321 - val_acc: 0.9605\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1101 - acc: 0.9670 - val_loss: 0.1499 - val_acc: 0.9568\n"
     ]
    }
   ],
   "source": [
    "train(mpl_3_layers_32['model'], mpl_3_layers_32['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_model(mpl_3_layers_32_model, 'mpl_3_layers_32.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.34117648,  0.4509804 ,  0.24705882,\n",
       "         0.18431373, -0.5294118 , -0.7176471 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.7411765 ,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "         0.8901961 ,  0.5529412 ,  0.5529412 ,  0.5529412 ,  0.5529412 ,\n",
       "         0.5529412 ,  0.5529412 ,  0.5529412 ,  0.5529412 ,  0.33333334,\n",
       "        -0.5921569 , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.4745098 , -0.10588235,\n",
       "        -0.43529412, -0.10588235,  0.2784314 ,  0.78039217,  0.99215686,\n",
       "         0.7647059 ,  0.99215686,  0.99215686,  0.99215686,  0.9607843 ,\n",
       "         0.79607844,  0.99215686,  0.99215686,  0.09803922, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.8666667 , -0.48235294, -0.8901961 , -0.4745098 ,\n",
       "        -0.4745098 , -0.4745098 , -0.5372549 , -0.8352941 ,  0.8509804 ,\n",
       "         0.99215686, -0.16862746, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.34901962,  0.9843137 ,  0.6392157 , -0.85882354,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.827451  ,  0.827451  ,\n",
       "         1.        , -0.34901962, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.01176471,  0.99215686,  0.8666667 , -0.654902  ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.5372549 ,  0.9529412 ,\n",
       "         0.99215686, -0.5137255 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.04313726,  0.99215686,  0.46666667, -0.9607843 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.92941177,  0.60784316,\n",
       "         0.94509804, -0.54509807, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.01176471,  0.99215686,  0.42745098, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.4117647 ,  0.96862745,\n",
       "         0.88235295, -0.5529412 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.8509804 ,  0.73333335,  0.99215686,  0.3019608 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.9764706 ,  0.5921569 ,  0.99215686,\n",
       "         0.7176471 , -0.7254902 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.7019608 ,  0.99215686,  0.99215686, -0.39607844, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.75686276,  0.75686276,  0.99215686,\n",
       "        -0.09803922, -0.99215686, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "         0.04313726,  0.99215686,  0.99215686, -0.5921569 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.52156866,  0.8980392 ,  0.99215686,\n",
       "         0.99215686, -0.5921569 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.05098039,  0.99215686,  0.99215686,  0.7176471 , -0.6862745 ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.05098039,  0.99215686,\n",
       "         0.62352943, -0.85882354, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_test[0]\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mpl_3_layers_32_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSERT_EQ_FLOAT(0.000001091, result[0]);\n",
      "ASSERT_EQ_FLOAT(0.000000000, result[1]);\n",
      "ASSERT_EQ_FLOAT(0.000027445, result[2]);\n",
      "ASSERT_EQ_FLOAT(0.000085699, result[3]);\n",
      "ASSERT_EQ_FLOAT(0.000000000, result[4]);\n",
      "ASSERT_EQ_FLOAT(0.000000037, result[5]);\n",
      "ASSERT_EQ_FLOAT(0.000000000, result[6]);\n",
      "ASSERT_EQ_FLOAT(0.999881625, result[7]);\n",
      "ASSERT_EQ_FLOAT(0.000003256, result[8]);\n",
      "ASSERT_EQ_FLOAT(0.000000857, result[9]);\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred[0])):\n",
    "    res = y_pred[0][i]\n",
    "    print('ASSERT_EQ_FLOAT({0:.9f}, result[{1}]);'.format(res, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
